# -*- coding: utf-8 -*-

from __future__ import division, print_function

"""
Script to train an RTE LSTM.

Input JSON files should be generated by the script `tokenize-corpus.py`.
"""

import argparse
import tensorflow as tf
import os
import time
import datetime
import logging
import logging.config

import ioutils
import utils
from classifiers import MultiFeedForwardClassifier
from tensorflow.contrib.framework.python.framework import checkpoint_utils

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('embeddings', help='Text or numpy file with word embeddings')
    parser.add_argument('mode', help='Word embedding for training')
    parser.add_argument('train', help='JSONL or TSV file with training corpus')
    parser.add_argument('validation', help='JSONL or TSV file with validation corpus')
    parser.add_argument('test', help='JSONL or TSV file with test corpus')
    parser.add_argument('save', help='Directory to save the model files')

    parser.add_argument('--vocab', help='Vocabulary file (only needed if numpy'
                                        'embedding file is given)')
    parser.add_argument('--load', help='pre-trained file')
    parser.add_argument('--is_train', default='1', type = int, help= 'whether train or not')
    parser.add_argument('-e', dest='num_epochs', default=100, type=int,
                        help='Number of epochs')
    parser.add_argument('-b', dest='batch_size', default=30, help='Batch size',
                        type=int)
    parser.add_argument('-u', dest='num_units', help='Number of hidden units',
                        default=200, type=int)
    parser.add_argument('-d', dest='dropout', help='Dropout keep probability',
                        default=0.8, type=float)
    parser.add_argument('-c', dest='clip_norm', help='Norm to clip training gradients',
                        default=None, type=float)
    parser.add_argument('-r', help='Learning rate', type=float, default=0.03,
                        dest='rate')
    parser.add_argument('-w', help='Numpy file with pretrained weights and biases '
                                   'for the LSTM', dest='weights')
    parser.add_argument('--no-proj', help='Do not project input embeddings to the '
                                          'same dimensionality used by internal networks',
                        action='store_false', dest='no_project', default=False)
    parser.add_argument('--lang', choices=['en', 'pt'], default='en',
                        help='Language (default en; only affects tokenizer)')
    parser.add_argument('--lower', help='Lowercase the corpus (use it if the embedding '
                                        'model is lowercased)', default= True, action='store_true')
    parser.add_argument('--use-intra', help='Use intra-sentence attention',
                        action='store_true', dest='use_intra', default=False)
    parser.add_argument('--l2', help='L2 normalization constant', type=float, default=0.0)
    parser.add_argument('--report', help='Number of batches between performance reports',
                        default=100, type=int)
    parser.add_argument('-v', help='Verbose', action='store_true', dest='verbose')
    parser.add_argument('--ratio', help='Train ratio', default=None)

    args = parser.parse_args()

    if not args.load:
        timestamp = (datetime.datetime.fromtimestamp(time.time()).strftime('%Y_%m_%d_%H_%M_%S'))
        args.save = args.save + "/" + timestamp
        os.mkdir(args.save)
        f = open(args.save + "/argument.txt", "w")
        for i in vars(args):
            f.write(str(i) + "\t" + str(vars(args)[i]) + "\n")
        f.close()
    else:
        args.save = args.load

    utils.config_logger(args.verbose)
    logger = utils.get_logger('train')
    logger.info('Reading training data')
    train_pairs, train_max = ioutils.read_corpus(args.train, args.lower, args.lang, args.ratio)
    logger.info('Reading validation data')
    valid_pairs, valid_max = ioutils.read_corpus(args.validation, args.lower, args.lang)
    logger.info('Reading test data')
    test_pairs, test_max = ioutils.read_corpus(args.test, args.lower, args.lang)
    logger.info('Reading word embeddings')
    word_dict, embeddings = ioutils.load_embeddings(args.embeddings, args.vocab)
    max_len = None
    #print(train_pairs)
    #embeddings = utils.normalize_embeddings(embeddings)
    logger.debug('Embeddings have shape {} (including unknown, padding and null)'
                 .format(embeddings.shape))

    logger.info('Converting words to indices')
    # find out which labels are there in the data (more flexible to different datasets)
    label_dict = utils.create_label_dict(train_pairs)
    train_data = utils.create_dataset(train_pairs, word_dict, label_dict, max_len, max_len)
    valid_data = utils.create_dataset(valid_pairs, word_dict, label_dict, max_len, max_len)
    test_data = utils.create_dataset(test_pairs, word_dict, label_dict, max_len, max_len)

    #print(train_data.sizes1)
    ioutils.write_extra_embeddings(embeddings, args.save)
    ioutils.write_params(args.save, lowercase=args.lower, language=args.lang, mode=args.mode)
    ioutils.write_label_dict(label_dict, args.save)
    weights, bias = ioutils.load_weights(args.weights)

    msg = '{} sentences have shape {} (firsts) and {} (seconds)'
    logger.debug(msg.format('Training',
                            train_data.sentences1.shape,
                            train_data.sentences2.shape))
    logger.debug(msg.format('Validation',
                            valid_data.sentences1.shape,
                            valid_data.sentences2.shape))
    logger.debug(msg.format('Test',
                            test_data.sentences1.shape,
                            test_data.sentences2.shape))

    sess = tf.InteractiveSession()
    logger.info('Creating model')
    vocab_size = embeddings.shape[0]
    embedding_size = embeddings.shape[1]

    model = MultiFeedForwardClassifier(args.num_units,
                           3, vocab_size, embedding_size, max_len,
                           use_intra_attention=args.use_intra,
                           training=True, learning_rate=args.rate,
                           clip_value=args.clip_norm, l2_constant=args.l2,
                           project_input=args.no_project, mode=args.mode)
    model.initialize(sess, embeddings)

    if args.load:
        vars = tf.contrib.framework.list_variables(args.load)
        # with tf.Graph().as_default(), tf.Session().as_default() as sess:
        #     new_vars = []
        #for name, shape in vars:
        #    print(name)
        #         v = tf.contrib.framework.load_variable(args.load, name)
        #         new_vars.append(tf.Variable(v, name = name.replace('biases', 'bias')))
        #     saver = tf.train.Saver(new_vars)
        #     sess.run(tf.global_variables_initializer())
        #     saver.save(sess, args.load + '/new-model')
        try:
            model.initialize_pretrain(sess, args.load)
        except:
            print('fail to load pre-train ...')

    total_params = 0
    for variable in tf.trainable_variables():
        shape = variable.get_shape()
        variable_params = 1
        for dim in shape:
            variable_params *= dim.value
        logger.debug('%s: %d params' % (variable.name, variable_params))
        total_params += variable_params

    logger.debug('Total parameters: %d' % total_params)

    if args.is_train:
        logger.info('Starting training')
        model.train(sess, train_data, valid_data, test_data, args.num_epochs, args.batch_size,
                    args.dropout, args.save, args.report)
    else:
        logger.info('Starting testing')
        model.test(sess, valid_data, test_data, args.batch_size,  args.save)

